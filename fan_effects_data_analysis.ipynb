{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyODj820eFcrsd4+KcAJuXWf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thaopham03/evaluating_fan_effects_in_large_language_models/blob/main/fan_effects_data_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l2TNNvjRw7vb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tqdm\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from pandas._libs.lib import is_timedelta_or_timedelta64_array\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "# import researchpy as rp\n",
        "import numpy as np\n",
        "import ast\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Assume all the results file are located in this dir:\n",
        "loc = \"/content/drive/MyDrive/IGOG-Alignment-Exp/Experiments/fan-effects-exp/results/rational/\""
      ],
      "metadata": {
        "id": "rm_vjNDR3RNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23ffa6c1-31ff-4adf-f6a8-7b1f77599303"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nbformat --upgrade\n",
        "!pip install seaborn --upgrade\n",
        "!pip install researchpy"
      ],
      "metadata": {
        "id": "9Nztqe6i3fze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out the elements from the result:\n",
        "\n",
        "truep_t = []  # true present, typical\n",
        "truep_at = [] # true present, atypical\n",
        "falsep_t = []  # false present, typical\n",
        "falsep_at = []  # false present, atypical\n",
        "truea_t = []  # true absent, typical\n",
        "truea_at = [] # true absent, atypical\n",
        "falsea_t = []  # false absent, typical\n",
        "falsea_at = [] # false absent, atypical\n",
        "\n",
        "# List of typical members:\n",
        "typical_members = [\"robin\",\"sparrow\",\"bluejay\",\"bluebird\",\"canary\",\"blackbird\",\"dove\",\"lark\",\"swallow\",\"parakeet\",\"oriole\",\"mockingbird\",\"redbird\", \"wren\",\n",
        "                   \"finch\",\"starling\",\"cardinal\",\"eagle\",\"hummingbird\",\"seagull\",\"woodpecker\",\"pigeon\",\"thrush\",\"falcon\",\"crow\",\"hawk\",\"raven\"]\n",
        "\n",
        "# List of atypical members:\n",
        "atypical_members = [\"goldfinch\",\"parrot\",\"sandpiper\",\"pheasant\",\"catbird\",\"crane\",\"albatross\",\"condor\",\"toucan\",\"owl\",\"pelican\",\"goose\",\"vulture\",\n",
        "                    \"stork\",\"buzzard\",\"swan\",\"flamingo\",\"duck\",\"peacock\",\"egret\",\"chicken\",\"turkey\",\"ostrich\",\"titmouse\",\"emu\",\"penguin\",\"bat\"]\n",
        "\n",
        "# Read the csv file:\n",
        "read_stimulus = pd.read_csv(loc+'roberta-base.csv',usecols=['stimulus'])\n",
        "read_item = pd.read_csv(loc+'roberta-base.csv',usecols=['item'])\n",
        "read_preamble = pd.read_csv(loc+'roberta-base.csv',usecols=['preamble'])\n",
        "read_score_val = pd.read_csv(loc+'roberta-base.csv',usecols=[\"score (sum, mean, [list)\"])\n",
        "\n",
        "# Split preamble into a list of just only items\n",
        "read_preamble['split_preamble'] = read_preamble['preamble'].apply(lambda x: x.split(\".\")[0][15:].split(\", \"))\n",
        "\n",
        "for i in range(len(read_item)):\n",
        "  item = read_item.at[i, 'item']\n",
        "  # split_preamble = read_preamble['preamble'].apply(lambda x: x.split(\".\")[0][15:].split(\", \"))\n",
        "  # split_preamble = split_preamble[15:].split(\", \")\n",
        "  split_preamble = read_preamble.at[i, 'split_preamble']\n",
        "  # preamble = read_preamble[i, 'split_preamble']\n",
        "  stimulus = read_stimulus.at[i, 'stimulus']\n",
        "  score_val = read_score_val.at[i, \"score (sum, mean, [list)\"]\n",
        "\n",
        "  if isinstance(score_val, str):\n",
        "        score_val = [(x.strip()) for x in score_val.strip('()').split(',')]\n",
        "\n",
        "  if item in split_preamble and stimulus == \"present.\":  # true present\n",
        "    if item in typical_members:\n",
        "      truep_t.append(score_val)\n",
        "    elif item in atypical_members:\n",
        "      truep_at.append(score_val)\n",
        "  elif item in split_preamble and stimulus == \"absent.\": # false absent\n",
        "    if item in typical_members:\n",
        "      falsea_t.append(score_val)\n",
        "    elif item in atypical_members:\n",
        "      falsea_at.append(score_val)\n",
        "  elif item not in split_preamble and stimulus == \"present.\": # false present\n",
        "    if item in typical_members:\n",
        "      falsep_t.append(score_val)\n",
        "    elif item in atypical_members:\n",
        "      falsep_at.append(score_val)\n",
        "  elif item not in split_preamble and stimulus == \"absent.\": # true absent\n",
        "    if item in typical_members:\n",
        "      truea_t.append(score_val)\n",
        "    elif item in atypical_members:\n",
        "      truea_at.append(score_val)\n"
      ],
      "metadata": {
        "id": "2VWsk1MNgH-f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "\n",
        "# Create a dictionary to store the lists\n",
        "map_df = {\n",
        "    'true_p_typical': truep_t,\n",
        "    'true_p_atypical': truep_at,\n",
        "    'false_p_typical': falsep_t,\n",
        "    'false_p_atypical': falsep_at,\n",
        "    'true_a_typical': truea_t,\n",
        "    'true_a_atypical': truea_at,\n",
        "    'false_a_typical': falsea_t,\n",
        "    'false_a_atypical': falsea_at\n",
        "}\n",
        "\n",
        "# Check the lengths of all lists\n",
        "list_lengths = [len(lst) for lst in [truep_t, truep_at, falsep_t, falsep_at, truea_t, truea_at, falsea_t, falsea_at]]\n",
        "\n",
        "# Ensure all lengths are equal\n",
        "max_length = max(list_lengths)\n",
        "for lst in [truep_t, truep_at, falsep_t, falsep_at, truea_t, truea_at, falsea_t, falsea_at]:\n",
        "    if len(lst) < max_length:\n",
        "        # Fill missing values with NaN\n",
        "        lst += [np.nan] * (max_length - len(lst))\n",
        "\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "df = pd.DataFrame(map_df)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB5h76m4kCsA",
        "outputId": "f8abf751-1380-4974-da33-28756e3b35d6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        true_p_typical  \\\n",
            "0    [[(-5.0703125, -2.53515625, [-5.0234375, -0.04...   \n",
            "1    [[(-4.0625, -2.03125, [-3.9375, -0.125]), (-4....   \n",
            "2    [[(-5.6328125, -2.81640625, [-5.5703125, -0.06...   \n",
            "3    [[(-4.90625, -2.453125, [-4.84375, -0.0625]), ...   \n",
            "4    [[(-6.0859375, -3.04296875, [-6.0390625, -0.04...   \n",
            "..                                                 ...   \n",
            "398                                                NaN   \n",
            "399                                                NaN   \n",
            "400                                                NaN   \n",
            "401                                                NaN   \n",
            "402                                                NaN   \n",
            "\n",
            "                                       true_p_atypical  \\\n",
            "0    [[(-4.28125, -2.140625, [-4.015625, -0.265625]...   \n",
            "1    [[(-3.8125, -1.90625, [-3.734375, -0.078125]),...   \n",
            "2    [[(-5.21875, -2.609375, [-5.140625, -0.078125]...   \n",
            "3    [[(-5.9765625, -2.98828125, [-5.8984375, -0.07...   \n",
            "4    [[(-4.375, -2.1875, [-4.265625, -0.109375]), (...   \n",
            "..                                                 ...   \n",
            "398                                                NaN   \n",
            "399                                                NaN   \n",
            "400                                                NaN   \n",
            "401                                                NaN   \n",
            "402                                                NaN   \n",
            "\n",
            "                                       false_p_typical  \\\n",
            "0    [[(-4.515625, -2.2578125, [-4.390625, -0.125])...   \n",
            "1    [[(-4.625, -2.3125, [-4.515625, -0.109375]), (...   \n",
            "2    [[(-4.6796875, -2.33984375, [-4.6328125, -0.04...   \n",
            "3    [[(-5.09375, -2.546875, [-4.921875, -0.171875]...   \n",
            "4    [[(-5.03125, -2.515625, [-4.9375, -0.09375]), ...   \n",
            "..                                                 ...   \n",
            "398  [[(-5.453125, -2.7265625, [-5.21875, -0.234375...   \n",
            "399  [[(-5.0234375, -2.51171875, [-4.9296875, -0.09...   \n",
            "400  [[(-4.3359375, -2.16796875, [-4.2578125, -0.07...   \n",
            "401  [[(-3.59375, -1.796875, [-3.53125, -0.0625]), ...   \n",
            "402  [[(-4.765625, -2.3828125, [-4.71875, -0.046875...   \n",
            "\n",
            "                                      false_p_atypical  \\\n",
            "0    [[(-6.15625, -3.078125, [-5.875, -0.28125]), (...   \n",
            "1    [[(-5.046875, -2.5234375, [-4.84375, -0.203125...   \n",
            "2    [[(-4.0625, -2.03125, [-4.015625, -0.046875]),...   \n",
            "3    [[(-4.2265625, -2.11328125, [-4.0390625, -0.18...   \n",
            "4    [[(-3.8046875, -1.90234375, [-3.7109375, -0.09...   \n",
            "..                                                 ...   \n",
            "398                                                NaN   \n",
            "399                                                NaN   \n",
            "400                                                NaN   \n",
            "401                                                NaN   \n",
            "402                                                NaN   \n",
            "\n",
            "                                        true_a_typical  \\\n",
            "0    [[(-2.6953125, -1.34765625, [-2.6328125, -0.06...   \n",
            "1    [[(-5.4375, -2.71875, [-5.359375, -0.078125]),...   \n",
            "2    [[(-3.6796875, -1.83984375, [-3.6484375, -0.03...   \n",
            "3    [[(-3.8984375, -1.94921875, [-3.8515625, -0.04...   \n",
            "4    [[(-4.0390625, -2.01953125, [-3.9609375, -0.07...   \n",
            "..                                                 ...   \n",
            "398  [[(-3.8125, -1.90625, [-3.765625, -0.046875]),...   \n",
            "399  [[(-3.7578125, -1.87890625, [-3.7265625, -0.03...   \n",
            "400  [[(-3.8125, -1.90625, [-3.75, -0.0625]), (-4.8...   \n",
            "401  [[(-3.5546875, -1.77734375, [-3.5078125, -0.04...   \n",
            "402  [[(-4.2421875, -2.12109375, [-4.2265625, -0.01...   \n",
            "\n",
            "                                       true_a_atypical  \\\n",
            "0    [[(-5.234375, -2.6171875, [-5.078125, -0.15625...   \n",
            "1    [[(-4.4375, -2.21875, [-4.34375, -0.09375]), (...   \n",
            "2    [[(-3.6953125, -1.84765625, [-3.6640625, -0.03...   \n",
            "3    [[(-4.6328125, -2.31640625, [-4.5546875, -0.07...   \n",
            "4    [[(-6.703125, -3.3515625, [-6.65625, -0.046875...   \n",
            "..                                                 ...   \n",
            "398                                                NaN   \n",
            "399                                                NaN   \n",
            "400                                                NaN   \n",
            "401                                                NaN   \n",
            "402                                                NaN   \n",
            "\n",
            "                                       false_a_typical  \\\n",
            "0    [[(-5.78125, -2.890625, [-5.65625, -0.125]), (...   \n",
            "1    [[(-4.4140625, -2.20703125, [-4.3984375, -0.01...   \n",
            "2    [[(-3.1171875, -1.55859375, [-3.0703125, -0.04...   \n",
            "3    [[(-4.59375, -2.296875, [-4.5, -0.09375]), (-5...   \n",
            "4    [[(-5.0, -2.5, [-4.921875, -0.078125]), (-5.62...   \n",
            "..                                                 ...   \n",
            "398                                                NaN   \n",
            "399                                                NaN   \n",
            "400                                                NaN   \n",
            "401                                                NaN   \n",
            "402                                                NaN   \n",
            "\n",
            "                                      false_a_atypical  \n",
            "0    [[(-3.796875, -1.8984375, [-3.71875, -0.078125...  \n",
            "1    [[(-4.515625, -2.2578125, [-4.34375, -0.171875...  \n",
            "2    [[(-4.8125, -2.40625, [-4.71875, -0.09375]), (...  \n",
            "3    [[(-5.5625, -2.78125, [-5.515625, -0.046875]),...  \n",
            "4    [[(-4.78125, -2.390625, [-4.75, -0.03125]), (-...  \n",
            "..                                                 ...  \n",
            "398                                                NaN  \n",
            "399                                                NaN  \n",
            "400                                                NaN  \n",
            "401                                                NaN  \n",
            "402                                                NaN  \n",
            "\n",
            "[403 rows x 8 columns]\n"
          ]
        }
      ]
    }
  ]
}