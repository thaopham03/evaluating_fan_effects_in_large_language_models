{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCjI+aJzPO99vokECM3x4F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thaopham03/evaluating_fan_effects_in_large_language_models/blob/main/fan_effects_data_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "l2TNNvjRw7vb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "\n",
        "from scipy.stats import spearmanr, pearsonr\n",
        "\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rm_vjNDR3RNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "946fbeff-4692-48ea-b596-f5d7541d53bf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filtering(file_name):\n",
        "\n",
        "  # Assume all the results file are located in this dir:\n",
        "  loc = \"/content/drive/MyDrive/IGOG-Alignment-Exp/Experiments/fan-effects-exp/results/rational/\"\n",
        "\n",
        "# Filter out the elements from the result:\n",
        "\n",
        "  truep_t = []  # true present, typical\n",
        "  truep_at = [] # true present, atypical\n",
        "  falsep_t = []  # false present, typical\n",
        "  falsep_at = []  # false present, atypical\n",
        "  truea_t = []  # true absent, typical\n",
        "  truea_at = [] # true absent, atypical\n",
        "  falsea_t = []  # false absent, typical\n",
        "  falsea_at = [] # false absent, atypical\n",
        "\n",
        "  # List of typical members:\n",
        "  typical_members = [\"robin\",\"sparrow\",\"bluejay\",\"bluebird\",\"canary\",\"blackbird\",\"dove\",\"lark\",\"swallow\",\"parakeet\",\"oriole\",\"mockingbird\",\"redbird\", \"wren\",\n",
        "                    \"finch\",\"starling\",\"cardinal\",\"eagle\",\"hummingbird\",\"seagull\",\"woodpecker\",\"pigeon\",\"thrush\",\"falcon\",\"crow\",\"hawk\",\"raven\"]\n",
        "\n",
        "  # List of atypical members:\n",
        "  atypical_members = [\"goldfinch\",\"parrot\",\"sandpiper\",\"pheasant\",\"catbird\",\"crane\",\"albatross\",\"condor\",\"toucan\",\"owl\",\"pelican\",\"goose\",\"vulture\",\n",
        "                      \"stork\",\"buzzard\",\"swan\",\"flamingo\",\"duck\",\"peacock\",\"egret\",\"chicken\",\"turkey\",\"ostrich\",\"titmouse\",\"emu\",\"penguin\",\"bat\"]\n",
        "\n",
        "  # Read the csv file:\n",
        "  read_stimulus = pd.read_csv(loc+file_name,usecols=['stimulus'])\n",
        "  read_item = pd.read_csv(loc+file_name,usecols=['item'])\n",
        "  read_preamble = pd.read_csv(loc+file_name,usecols=['preamble'])\n",
        "  read_score_val = pd.read_csv(loc+file_name,usecols=[\"score (sum, mean, [list)\"])\n",
        "\n",
        "  # Split preamble into a list of just only items\n",
        "  read_preamble['split_preamble'] = read_preamble['preamble'].apply(lambda x: x.split(\".\")[0][15:].split(\", \"))\n",
        "\n",
        "  for i in range(len(read_item)):\n",
        "    item = read_item.at[i, 'item']\n",
        "    # split_preamble = read_preamble['preamble'].apply(lambda x: x.split(\".\")[0][15:].split(\", \"))\n",
        "    # split_preamble = split_preamble[15:].split(\", \")\n",
        "    split_preamble = read_preamble.at[i, 'split_preamble']\n",
        "    # preamble = read_preamble[i, 'split_preamble']\n",
        "    stimulus = read_stimulus.at[i, 'stimulus']\n",
        "    score_val = read_score_val.at[i, \"score (sum, mean, [list)\"]\n",
        "\n",
        "    if isinstance(score_val, str):\n",
        "      # Extracting the mean value from the score string\n",
        "      score_val = score_val.strip('[]()').split(',')[1].strip()\n",
        "      score_val = float(score_val)\n",
        "\n",
        "    if item in split_preamble and stimulus == \"present.\":  # true present\n",
        "      if item in typical_members:\n",
        "        truep_t.append(score_val)\n",
        "      elif item in atypical_members:\n",
        "        truep_at.append(score_val)\n",
        "    elif item in split_preamble and stimulus == \"absent.\": # false absent\n",
        "      if item in typical_members:\n",
        "        falsea_t.append(score_val)\n",
        "      elif item in atypical_members:\n",
        "        falsea_at.append(score_val)\n",
        "    elif item not in split_preamble and stimulus == \"present.\": # false present\n",
        "      if item in typical_members:\n",
        "        falsep_t.append(score_val)\n",
        "      elif item in atypical_members:\n",
        "        falsep_at.append(score_val)\n",
        "    elif item not in split_preamble and stimulus == \"absent.\": # true absent\n",
        "      if item in typical_members:\n",
        "        truea_t.append(score_val)\n",
        "      elif item in atypical_members:\n",
        "        truea_at.append(score_val)\n",
        "  # Visualization\n",
        "\n",
        "  # Create a dictionary to store the lists\n",
        "  map_df = {\n",
        "      'true_p_typical': truep_t,\n",
        "      'true_p_atypical': truep_at,\n",
        "      'false_p_typical': falsep_t,\n",
        "      'false_p_atypical': falsep_at,\n",
        "      'true_a_typical': truea_t,\n",
        "      'true_a_atypical': truea_at,\n",
        "      'false_a_typical': falsea_t,\n",
        "      'false_a_atypical': falsea_at\n",
        "  }\n",
        "\n",
        "  # Check the lengths of all lists\n",
        "  list_lengths = [len(lst) for lst in map_df.values()]\n",
        "\n",
        "  # Ensure all lengths are equal\n",
        "  max_length = max(list_lengths)\n",
        "  for lst in [truep_t, truep_at, falsep_t, falsep_at, truea_t, truea_at, falsea_t, falsea_at]:\n",
        "      if len(lst) < max_length:\n",
        "          # Fill missing values with NaN\n",
        "          lst += [np.nan] * (max_length - len(lst))\n",
        "\n",
        "\n",
        "  # Convert the dictionary to a DataFrame\n",
        "  df = pd.DataFrame(map_df)\n",
        "  print(df)\n"
      ],
      "metadata": {
        "id": "2VWsk1MNgH-f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  print(\"Mistral\")\n",
        "  filtering('mistralai_Mistral-7B-v0.1.csv')\n",
        "  print(\"Llama-2\")\n",
        "  filtering('meta-llama_Llama-2-7b-hf.csv')\n",
        "  print(\"Llama-3\")\n",
        "  filtering('meta-llama_Meta-Llama-3-8B.csv')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB5h76m4kCsA",
        "outputId": "ce871efc-dce5-4f93-cf7a-f68f2a71777e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mistral\n",
            "     true_p_typical  true_p_atypical  false_p_typical  false_p_atypical  \\\n",
            "0         -9.099177        -3.295715        -9.209574         -9.275753   \n",
            "1         -8.862229        -3.891313        -8.461470         -8.345871   \n",
            "2         -9.323246        -8.800889        -8.458887         -9.848536   \n",
            "3        -10.051567        -7.738414        -8.897091         -9.486038   \n",
            "4         -9.397378        -9.446735        -7.753295         -8.804101   \n",
            "..              ...              ...              ...               ...   \n",
            "398             NaN              NaN        -8.450175               NaN   \n",
            "399             NaN              NaN        -9.474573               NaN   \n",
            "400             NaN              NaN        -7.604613               NaN   \n",
            "401             NaN              NaN       -10.382090               NaN   \n",
            "402             NaN              NaN        -9.142367               NaN   \n",
            "\n",
            "     true_a_typical  true_a_atypical  false_a_typical  false_a_atypical  \n",
            "0        -10.124681        -9.291286       -10.254365         -4.903983  \n",
            "1        -10.806415        -8.873212        -9.742514         -4.132584  \n",
            "2         -8.511209        -8.783724       -10.617372         -8.570434  \n",
            "3         -8.845812        -7.485436       -10.125923         -4.813241  \n",
            "4         -8.465866        -8.923815       -10.316401         -9.191698  \n",
            "..              ...              ...              ...               ...  \n",
            "398       -8.044329              NaN              NaN               NaN  \n",
            "399      -10.111319              NaN              NaN               NaN  \n",
            "400       -9.094070              NaN              NaN               NaN  \n",
            "401      -10.078512              NaN              NaN               NaN  \n",
            "402       -9.084723              NaN              NaN               NaN  \n",
            "\n",
            "[403 rows x 8 columns]\n",
            "Llama-2\n",
            "     true_p_typical  true_p_atypical  false_p_typical  false_p_atypical  \\\n",
            "0         -3.105361        -2.971195        -4.264892         -2.790167   \n",
            "1         -3.554093        -3.763555        -3.363866         -3.161967   \n",
            "2         -4.177814        -2.919127        -3.531226         -2.900464   \n",
            "3         -3.731156        -3.944731        -3.681390         -3.024206   \n",
            "4         -3.211723        -3.794254        -3.678535         -3.235707   \n",
            "..              ...              ...              ...               ...   \n",
            "398             NaN              NaN        -4.720099               NaN   \n",
            "399             NaN              NaN        -3.573083               NaN   \n",
            "400             NaN              NaN        -3.885126               NaN   \n",
            "401             NaN              NaN        -3.764012               NaN   \n",
            "402             NaN              NaN        -2.938670               NaN   \n",
            "\n",
            "     true_a_typical  true_a_atypical  false_a_typical  false_a_atypical  \n",
            "0         -2.777440        -3.975739        -2.914798         -3.847813  \n",
            "1         -3.569516        -1.850572        -3.453352         -4.110501  \n",
            "2         -2.380604        -2.539073        -4.507134         -3.411344  \n",
            "3         -3.306644        -3.025345        -3.137074         -3.866789  \n",
            "4         -2.475554        -3.515750        -4.033030         -4.284968  \n",
            "..              ...              ...              ...               ...  \n",
            "398       -3.453805              NaN              NaN               NaN  \n",
            "399       -4.313003              NaN              NaN               NaN  \n",
            "400             NaN              NaN              NaN               NaN  \n",
            "401       -3.875625              NaN              NaN               NaN  \n",
            "402       -4.578992              NaN              NaN               NaN  \n",
            "\n",
            "[403 rows x 8 columns]\n",
            "Llama-3\n",
            "     true_p_typical  true_p_atypical  false_p_typical  false_p_atypical  \\\n",
            "0         -4.046040        -4.261001        -3.623718         -4.272047   \n",
            "1         -3.505323        -3.530377        -4.838032         -3.763396   \n",
            "2         -3.963573        -4.000645        -2.857119         -3.414619   \n",
            "3         -4.888213        -4.680981        -4.208851         -3.287338   \n",
            "4         -3.929367        -4.018771        -3.500946         -2.731446   \n",
            "..              ...              ...              ...               ...   \n",
            "398             NaN              NaN        -3.982691               NaN   \n",
            "399             NaN              NaN        -4.119071               NaN   \n",
            "400             NaN              NaN        -3.375888               NaN   \n",
            "401             NaN              NaN        -4.477157               NaN   \n",
            "402             NaN              NaN        -4.231842               NaN   \n",
            "\n",
            "     true_a_typical  true_a_atypical  false_a_typical  false_a_atypical  \n",
            "0         -3.225016        -4.260798        -5.493647         -4.513700  \n",
            "1         -3.370933        -2.613835        -4.346255         -3.779163  \n",
            "2         -3.236551        -3.079465        -3.989468         -4.073149  \n",
            "3         -4.326294        -3.727324        -4.686756         -4.027679  \n",
            "4         -3.151791        -2.447133        -5.007531         -3.984116  \n",
            "..              ...              ...              ...               ...  \n",
            "398       -5.039498              NaN              NaN               NaN  \n",
            "399       -4.692276              NaN              NaN               NaN  \n",
            "400       -4.429085              NaN              NaN               NaN  \n",
            "401       -4.935886              NaN              NaN               NaN  \n",
            "402       -4.540736              NaN              NaN               NaN  \n",
            "\n",
            "[403 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_file, drop_cols=['preamble'], convert_prob=True):\n",
        "    data = pd.read_csv(data_file, sep='|')\n",
        "    data = data.drop(drop_cols, axis=1)\n",
        "\n",
        "    try:\n",
        "        data['stimulus'] = [[t for t in m] for m in data['stimulus'].apply(ast.literal_eval)]\n",
        "    except ValueError as e:\n",
        "        for m in data['stimulus_prob']:\n",
        "            print(m)\n",
        "        print(data['stimulus_prob'])\n",
        "        return None\n",
        "\n",
        "    if convert_prob:\n",
        "        data['stimulus_prob'] = [[(2 ** t) for t in m] for m in data['stimulus_prob']]\n",
        "\n",
        "    return pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "_HbvFwdc0Btr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_confusion_matrix(df):\n",
        "    test_pos = df.loc[(df['Dependent_Variable'] == 'present.')]\n",
        "    test_neg = df.loc[(df['Dependent_Variable'] == 'absent.')]\n",
        "\n",
        "    true_neg  = test_neg.loc[(test_neg['True_Category'] ==  'absent')].reset_index()\n",
        "    false_pos = test_pos.loc[(test_pos['True_Category'] ==  'absent')].reset_index()\n",
        "    false_neg = test_neg.loc[(test_neg['True_Category'] == 'present')].reset_index()\n",
        "    true_pos  = test_pos.loc[(test_pos['True_Category'] == 'present')].reset_index()\n",
        "\n",
        "    # Decided to return in the same order expected from sklearn confusion_matrix function\n",
        "    return true_neg, false_pos, false_neg, true_pos"
      ],
      "metadata": {
        "id": "KlhmfQzQ1b0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion_scatter(df, fan_type = 'both', aggregate='none'):\n",
        "    if fan_type == 'both':\n",
        "        fan = lambda a, b : (a*a + b*b)**(1/2)\n",
        "    elif fan_type == 'first':\n",
        "        fan = lambda a, b : a\n",
        "    elif fan_type == 'second':\n",
        "        fan = lambda a, b : b\n",
        "\n",
        "    def fill_subplot(ax, df_part : pd.DataFrame, lab):\n",
        "        x = []\n",
        "        y = []\n",
        "\n",
        "        for _, row in df_part.iterrows():\n",
        "            fan_per = row['Fan_Person']\n",
        "            fan_pla = row['Fan_Place']\n",
        "            probs = row['stimulus_prob']\n",
        "\n",
        "            if len(probs) != 50:\n",
        "                raise ValueError\n",
        "\n",
        "            if aggregate == 'none':\n",
        "                x = x + [fan(fan_per, fan_pla)] * len(probs)\n",
        "                y = y + probs\n",
        "            elif aggregate == 'mean':\n",
        "              x = x + [fan(fan_per, fan_pla)]\n",
        "                y = y + [np.mean(probs)]\n",
        "            elif aggregate == 'std':\n",
        "                x = x + [fan(fan_per, fan_pla)]\n",
        "                y = y + [np.std(probs)]\n",
        "\n",
        "        x, y = np.asarray(x), np.asarray(y)\n",
        "\n",
        "        m, b = np.polyfit(x, y, 1)\n",
        "        # r, p = spearmanr(x, y)\n",
        "\n",
        "        # z = spearmanr(x, y)\n",
        "        z = pearsonr(x, y)\n",
        "        r = z.statistic\n",
        "        p = z.pvalue\n",
        "\n",
        "        # ax.scatter(x,y, color=(0,0,0,max(0.1,1/len(x))))\n",
        "\n",
        "        bins = dict()\n",
        "        for x_i, y_i in zip(x,y):\n",
        "          try:\n",
        "                bins[x_i].append(y_i)\n",
        "            except KeyError:\n",
        "                bins[x_i] = [y_i]\n",
        "\n",
        "        sorted_x = list(sorted(list(set(x))))\n",
        "        new_y = [bins[k] for k in sorted_x]\n",
        "\n",
        "\n",
        "        ax.violinplot(new_y, [50 * k for k in sorted_x])\n",
        "\n",
        "        ax.plot(x, m*x + b, color='red')\n",
        "        ax.text(0.01,0.01, f'r={r:.3f}, p={p:.3f} g={lab}', color='red', transform=ax.transAxes)\n",
        "\n",
        "    tn, fp, fn, tp = split_confusion_matrix(df)\n",
        "\n",
        "    fig, axes = plt.subplots(nrows = 2, ncols = 2, figsize=(15,15))\n",
        "\n",
        "    fill_subplot(axes[0][0], tp, 'tp')\n",
        "    # fill_subplot(axes[0][1], fn, 'fn')\n",
        "    # fill_subplot(axes[1][0], fp, 'fp')\n",
        "    # fill_subplot(axes[1][1], tn, 'tn')\n",
        "\n",
        "    plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "hO3CN9vs1ewp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def per_pop_corr (df, fan_type = 'both'):\n",
        "    if fan_type == 'both':\n",
        "        fan = lambda a, b : (a*a + b*b)**(1/2)\n",
        "    elif fan_type == 'first':\n",
        "        fan = lambda a, b : a\n",
        "    elif fan_type == 'second':\n",
        "        fan = lambda a, b : b\n",
        "\n",
        "    _, _, _, df_part = split_confusion_matrix(df)\n",
        "\n",
        "    # fig, ax = plt.subplots(nrows = 2, ncols = 2, figsize=(10,10))\n",
        "    # fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize=(10,10))\n",
        "\n",
        "\n",
        "    pop_size = len(df_part['stimulus_prob'][0])\n",
        "    x = []\n",
        "    y_list = [[] for _ in range(pop_size)]\n",
        "    for _, row in df_part.iterrows():\n",
        "        fan_per = row['Fan_Person']\n",
        "        fan_pla = row['Fan_Place']\n",
        "        probs = row['stimulus_prob']\n",
        "\n",
        "        x = x + [fan(fan_per, fan_pla)]\n",
        "        for i in range(pop_size):\n",
        "            y_list[i].append(probs[i])\n",
        "\n",
        "    # x, y = np.asarray(x), np.asarray(y)\n",
        "\n",
        "    # m, b = np.polyfit(x, y, 1)\n",
        "\n",
        "    rs, ps = [], []\n",
        "    # z = spearmanr(x, y)\n",
        "    # z = pearsonr(x, y)\n",
        "    # r = z.statistic\n",
        "    # p = z.pvalue\n",
        "\n",
        "    for i in range(pop_size):\n",
        "        # z = spearmanr(x, y_list[i])\n",
        "        z = pearsonr(x, y_list[i])\n",
        "        rs.append(z.statistic)\n",
        "        ps.append(z.pvalue)\n",
        "\n",
        "    return rs, ps\n",
        "\n",
        "    ax.scatter(x,y, color=(0,0,0,max(0.1,1/len(x))))\n",
        "    ax.plot(x, m*x + b, color='red')\n",
        "    ax.text(0.01,0.01, f'r={r:.3f}, p={p:.3f} g=tp', color='red', transform=ax.transAxes)\n",
        "\n",
        "    ax.set_xlabel('Fan Level')\n",
        "    ax.set_ylabel('Probability')\n",
        "    ax.set_xlim(0,None)\n",
        "    ax.set_ylim(0,None)\n",
        "\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "r9biu9jP1-oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "    # 'LLaMa2-7B',\n",
        "    # 'LLaMa3-8B',\n",
        "    # 'LLaMa3-8B-Instruct',\n",
        "    'Mistral-7B',\n",
        "]"
      ],
      "metadata": {
        "id": "ZjvTj30w2Hag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for mod in models:\n",
        "    df = load_data(f'../data/Random_TP_Only/results_{mod}.csv', convert_prob=True)\n",
        "    exp_rs, exp_ps = per_pop_corr(df, fan_type='both')\n",
        "    print(f'Model: {mod}\\tfan type: both')\n",
        "    print(np.asarray(exp_rs))\n",
        "    print(np.mean(exp_rs))\n",
        "    print(np.std(exp_rs))\n",
        "\n",
        "    exp_rs, exp_ps = per_pop_corr(df, fan_type='first')\n",
        "    print(f'Model: {mod}\\tfan type: first')\n",
        "    print(np.asarray(exp_rs))\n",
        "    print(np.mean(exp_rs))\n",
        "    print(np.std(exp_rs))\n",
        "\n",
        "    exp_rs, exp_ps = per_pop_corr(df, fan_type='second')\n",
        "    print(f'Model: {mod}\\tfan type: second')\n",
        "    print(np.asarray(exp_rs))\n",
        "    print(np.mean(exp_rs))\n",
        "    print(np.std(exp_rs))\n",
        "\n",
        "    print()"
      ],
      "metadata": {
        "id": "E3ZYHG_E2K_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_mist = load_data('../data/Random/results_Mistral-7B.csv', convert_prob=True)"
      ],
      "metadata": {
        "id": "VqHzGf-s2OIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_mist = load_data('../data/Random_TP_Only/results_Mistral-7B.csv', convert_prob=True)\n",
        "confusion_scatter(rand_mist, fan_type='both', aggregate='std')\n",
        "confusion_scatter(rand_mist, fan_type='first', aggregate='std')\n",
        "confusion_scatter(rand_mist, fan_type='second', aggregate='std')"
      ],
      "metadata": {
        "id": "mnzszs8F2RCy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}